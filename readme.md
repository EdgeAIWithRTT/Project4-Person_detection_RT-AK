<center><h1>Person detection</h1></center>

> è®© AI åœ¨ä½ çš„æ¿å­ä¸Šå°½æƒ…èˆè¹ˆ~
>
> æœ¬æ¬¡å®éªŒçš„æ˜¯è¯†åˆ«æ‘„åƒå¤´ä¸­çš„äººï¼Œå°±ä¸€ä¸ªäººï¼Œè€Œä¸æ˜¯å¤šä¸ªã€‚
>
> ä»å¤šç±»åˆ«æ£€æµ‹æ¨¡å‹æ”¹ç¼–è€Œæ¥ï¼Œåªä¿ç•™ person è¿™ä¸ªç±»åˆ«ï¼Œæ ¹æ®å„ä½çœ‹å®˜çš„èƒ½åŠ›å®Œå…¨å¯ä»¥æ”¹æˆè¯†åˆ«å¤šç±»

æœ¬æ¬¡é¡¹ç›®çš„ç¯‡å¹…å°†ä¼šè¾ƒé•¿ï¼Œè¯·å„ä½çœ‹å®˜è€å¿ƒçœ‹å®Œ

æ•´ä½“åˆ†ä¸ºä¸‰éƒ¨åˆ†ï¼š

1. [æ¨¡å‹](#1-æ¨¡å‹)
2. [RT-AK ä½¿ç”¨](#2-RT-AK ä½¿ç”¨)
3. [æ¿å­ä¸Šçš„åº”ç”¨å±‚ä»£ç å®ç°](#3-åº”ç”¨ä»£ç )

ç¡¬ä»¶å¹³å° ART-Pi, 50M FLOPSã€‚

**æˆ‘çš„æ¨¡å‹ï¼ˆåˆ å‡åçš„æ¨¡å‹ï¼‰**æœ€ç»ˆéƒ¨ç½²åœ¨æ¿å­ä¸Šæ˜¯**æ¨ç†æ—¶é—´**æ˜¯56msï¼Œä¸åŒ…æ‹¬æ•°æ®å¤„ç†æ—¶é—´ã€‚

- pc ç«¯æ¨ç†ä¸€å¼ å›¾ç‰‡ï¼š

```shell
$ pip install -r requirements.txt
$ python inference_yolo-s.py
```

![](./imgs/yolo-s_prediction.jpg)

- ä»¥ä¸‹æ˜¯åœ¨ ART-PI ä¸Šçš„æ¨¡å‹æ¨ç†å®ç°ï¼š

![demo](./imgs/demo.gif)

# 1 æ¨¡å‹

## 1.1 å‚è€ƒé¡¹ç›®

> å‚è€ƒé¡¹ç›®ï¼š[Yolo-Fastest](https://github.com/dog-qiuqiu/Yolo-Fastest) & [[keras-YOLOv3-model-set](https://github.com/david8862/keras-YOLOv3-model-set)](https://github.com/david8862/keras-YOLOv3-model-set)

åŸå› ï¼šç›®å‰äº†è§£çš„å…¨ç½‘æœ€è½»é‡çº§çš„ç›®æ ‡æ£€æµ‹ç½‘ç»œï¼Œæ²¡æœ‰ä¹‹ä¸€

> ç°åœ¨ä¸æ˜¯äº†ï¼Œå‡ºç°äº†ä¸€ä¸ª ppyoloï¼Œç™¾åº¦äº§

| Network                     | Model Size | mAP(VOC 2017) | FLOPS      |
| --------------------------- | ---------- | ------------- | ---------- |
| Tiny YOLOv2                 | 60.5MB     | 57.1%         | 6.97BFlops |
| Tiny YOLOv3                 | 33.4MB     | 58.4%         | 5.52BFlops |
| YOLO Nano                   | 4.0MB      | 69.1%         | 4.51Bflops |
| MobileNetv2-SSD-Lite        | 13.8MB     | 68.6%         | &Bflops    |
| MobileNetV2-YOLOv3          | 11.52MB    | 70.20%        | 2.02Bflos  |
| Pelee-SSD                   | 21.68MB    | 70.09%        | 2.40Bflos  |
| ***Yolo Fastest***          | 1.3MB      | 61.02%        | 0.23Bflops |
| ***Yolo Fastest-XL***       | 3.5MB      | 69.43%        | 0.70Bflops |
| ***MobileNetv2-Yolo-Lite*** | 8.0MB      | 73.26%        | 1.80Bflops |

å½“ç„¶ï¼ŒYolo Fastest æœ€å°çš„æ¨¡å‹ä¹Ÿæœ‰ 0.23 Bflopsï¼Œæƒ³è¦åœ¨ ART-Pi ä¸Šé¡ºåˆ©çš„è·‘èµ·æ¥ï¼Œè‚‰çœ¼å¯è§çš„ä¸æ»‘ç¨‹åº¦ï¼Œæˆ‘æ˜¯åœ¨åšæ¢¦ã€‚ã€‚ã€‚

è¿™æ—¶å€™æœ‰ä¸¤ä¸ªåŠæ³•ï¼š

1. æ¢ä¸€å—æ¿å­ï¼Œæ¢ä¸€å—ç®—åŠ›æ›´å¤§çš„æ¿å­ã€‚
2. å°†æ¨¡å‹æ”¹çš„å°ä¸€ç‚¹ï¼Œèƒ½å¤Ÿåœ¨ ART-PI ä¸Šä¸æ»‘çš„è·‘èµ·æ¥ã€‚

è¿™é‡Œæˆ‘é€‰æ‹©çš„æ˜¯åè€…ã€‚

æˆ‘æ”¹åŠ¨çš„å¾ˆç®€å•ï¼Œå»æ‰ç‰¹å¾é‡‘å­—å¡”è¾“å‡ºï¼Œåªä¿ç•™ä¸€ä¸ªè¾“å‡ºï¼Œä¿è¯å¯¹å¤§ç‰©ä½“æ£€æµ‹å‹å¥½å³å¯ã€‚åŒæ—¶åˆ å‡ç½‘ç»œç»“æ„ã€‚åŸæ¥æ˜¯109å±‚ï¼Œæˆ‘æ˜¯20+å±‚ç½‘ç»œç»“æ„ã€‚

çº æ­£ä¸€ä¸ªæ€æƒ³è¯¯åŒºï¼Œç”±äºä¸€äº›å¾ˆç¥å¥‡çš„å­˜åœ¨ï¼Œç½‘ç»œå¹¶ä¸æ˜¯è¶Šæ·±ï¼Œ`FLOPS` å°±ä¼šè¶Šå¤§ï¼Œæ¯”å¦‚ `DSCNN`ã€‚

---

ç¬¬äºŒä¸ªå‚è€ƒé¡¹ç›®çš„æ„ä¹‰æ˜¯åœ¨äºï¼šå°†æ¨¡å‹è½¬å˜ä¸º `tflite` å¯é£Ÿç”¨æ¨¡å‹

## 1.2 æ¨¡å‹æ–‡ä»¶

- æˆ‘æ”¹åŠ¨çš„æ¨¡å‹é…ç½®æ–‡ä»¶ï¼š`./model/yolo-s_with_lrelu.cfg` 

  > åŸæ¨¡å‹é…ç½®æ–‡ä»¶ï¼š`./model/VOC`
  >
  > ä¸ºäº†é˜²æ­¢åœ¨åæœŸæ¨¡å‹è½¬æ¢çš„è¿‡ç¨‹ä¸­é‡åˆ°ä¸æ”¯æŒçš„ç®—å­ï¼š`leakyrelu`ï¼Œæˆ‘è¿™é‡Œæä¾›äº†ä¸€ä»½ `relu` çš„æ¨¡å‹è®­ç»ƒé…ç½®æ–‡ä»¶

- é¢„å…ˆè®­ç»ƒå¥½çš„æ¨¡å‹ï¼š`./model/yolo-s.h5` 507 kï¼Œé‡åŒ–çš„ `tflite` æ¨¡å‹æ–‡ä»¶ï¼š`./model/yolo-s.tflite` 144 k

## 1.3 è‡ªå·±è®­ç»ƒæ¨¡å‹

è¯·å‚è€ƒï¼š [Yolo-Fastest](https://github.com/dog-qiuqiu/Yolo-Fastest) é¡¹ç›® 

æˆ‘è‡ªå·±ä¹Ÿå†™è¿‡ä¸€ä»½[å¿«é€Ÿä¸Šæ‰‹ yolo-fastest æ•™ç¨‹](https://blog.csdn.net/weixin_37598106/article/details/112544854?spm=1001.2014.3001.5501)ï¼Œ ä½†æ˜¯ç”±äº up ä¸»æ›´æ–°çš„æ¯”è¾ƒå¿«ï¼Œå¯èƒ½æœ‰ä¸€äº›ç‰ˆæœ¬è½åï¼Œä»…ä¾›å‚è€ƒã€‚

1. éœ€è¦é…ç½® `darknet` è®­ç»ƒç¯å¢ƒï¼Œç„¶åæ ¹æ®éœ€æ±‚ä¿®æ”¹ä¸‹  `cfg` æ–‡ä»¶å³å¯

2. å‡†å¤‡æ•°æ®é›†ï¼š`VOC 2007 + VOC 2012`

    ```shell
    wget https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar
    wget https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar
    wget https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar
    tar xf VOCtrainval_11-May-2012.tar
    tar xf VOCtrainval_06-Nov-2007.tar
    tar xf VOCtest_06-Nov-2007.tar

    wget https://pjreddie.com/media/files/voc_label.py
    # ä¿®æ”¹æ–‡ä»¶ï¼Œå°†é‡Œé¢çš„ç±»åˆ«åªä¿ç•™ person ç±»åˆ«
    python voc_label.py

    cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt
    ```

â€‹	ä¿®æ”¹ `./model/voc_person.data` ä¸­çš„ `train` å’Œ `valid` è·¯å¾„ï¼Œæ³¨æ„ï¼Œå¦‚æœä½ ä¸æ˜¯è®­ç»ƒ `person`  å•ç±»åˆ«ï¼Œè¯·ä¸€å¹¶ä¿®æ”¹ `voc_person.names` æ–‡ä»¶

3. è®­ç»ƒ

    ```shell
    $ ./darknet detector train <data_path> <cfg_path> 

    # ä¸¾ä¾‹ï¼Œ -dont_show æ˜¯ä¸æ˜¾ç¤ºå›¾ç‰‡ï¼Œ -gpus æ˜¯æŒ‡å®š gpu è®­ç»ƒ
    $ ./darknet detector train voc_person.data yolo-s.cfg -dont_show -gpus 0, 1
    ```

4. æµ‹è¯•

    > `perons.jpg` ä½äº `./imgs`

    ```shell
    # test 1 image
    ./darknet detector test voc_person.data yolo-s.cfg yolo-s_last.weights person.jpg -thresh 0.5 -dont_show

    # mAP
    ./darknet detector map voc_person.data yolo-s.cfg yolo-s_last.weights -points 11
    ```

    ![](./imgs/yolo-s_output.png)

    æ¨¡å‹è½¬æ¢æˆ `keras`ï¼Œæœ€åè½¬æˆ `tflite`

    > å¯¹åº”çš„ä»£ç ä»“åº“ï¼š[Lebhoryi/keras-YOLOv3-model-set](https://github.com/Lebhoryi/keras-YOLOv3-model-set)ï¼Œ
    >
    > è½¬è‡ª [david8862/keras-YOLOv3-model-set](https://github.com/david8862/keras-YOLOv3-model-set) ï¼Œæˆ‘åšäº†ä¸€äº›ä¿®æ”¹ï¼Œè¯·æŒ‰ç…§æˆ‘çš„æ¥ï¼Œå¦åˆ™å‡ºé”™è¯·è‡ªè´ŸğŸ˜‚ğŸ˜‚ğŸ˜‚

    ```shell
    # yolo-fastest to keras
    python tools/model_converter/convert.py cfg/yolo-s.cfg weights/yolo-s_last.weights weights/yolo-s.h5 Â -f -c

    # keras to tflite
    python tools/model_converter/custom_tflite_convert.py --keras_model_file ./weights/yolo-s.h5 --output_file ./weights/yolo-s.tflite

    # keras to tflite; quantize
    python tools/model_converter/post_train_quant_convert.py --keras_model_file ./weights/yolo-s.h5 --annotation_file /home/lebhoryi/Data/VOC/2007_test.txt --model_input_shape 160x160 --sample_num 30 --output_file ./weights/yolo-s.tflite -c
    ```

  # 2 RT-AK ä½¿ç”¨

å…·ä½“ä½¿ç”¨è¯·æŸ¥é˜… [RT-Thread/RT-AK](https://github.com/RT-Thread/RT-AK) ç›¸å…³æ–‡æ¡£

å‡†å¤‡ï¼š

- ART-PI bsp
- æ¨¡å‹
- RT-AK

ä½¿ç”¨ï¼š

  ```shell
$ git clone https://github.com/RT-Thread/RT-AK

$ cd RT-AK/RT-AK/rt_ai_tools

# åªéœ€è¦æ”¹åŠ¨ --modelã€--projectã€--ext_tools ä¸‰ä¸ªå‚æ•°çš„è·¯å¾„å³å¯
$ python aitools.py --model=./yolo-s.h5 --model_name=person_yolo --project=D:\RT-ThreadStudio\workspace\art-pi --platform stm32 --ext_tools="D:\Program Files (x86)\stm32ai-windows-5.2.0\windows" --clear
  ```

 # 3 åº”ç”¨ä»£ç 

> æˆ‘çš„è¾“å…¥æ˜¯ 160x160x1ï¼Œä¸ºäº†å‡å°æ¨¡å‹å‚æ•°å¤§å°ï¼Œ

å…ˆåœ¨ pc ç«¯å®ç°åº”ç”¨å±‚çš„ä»£ç 

- [x] å›¾ç‰‡é¢„å¤„ç†ï¼šå°ºåº¦ç¼©æ”¾+ç°åº¦è½¬åŒ–+å½’ä¸€åŒ–
- [x] yolo è§£ç 
- [x] nms å¤„ç†

ä»£ç éƒ½åœ¨ `inference_yolo-s.py` ä¸­ã€‚

æ‰‹è¾¹æ²¡æœ‰ `usb` æ‘„åƒå¤´ï¼Œä¹Ÿå°±æ²¡æœ‰å†™è§†é¢‘çš„æ¨ç†ä»£ç ï¼Œåªæœ‰å›¾ç‰‡çš„æ¨ç†ä»£ç ã€‚

åŠŸèƒ½å®ç°ï¼š

1. å›¾ç‰‡é¢„å¤„ç†

   `python` é‡Œå¤´å°±å¾ˆç®€å•ï¼Œè°ƒç”¨ `opencv` åº“ï¼Œå‡ è¡Œä»£ç æå®š

   ```python
   img_raw = cv2.imread(str(img_path))
   img = cv2.cvtColor(img_raw, cv2.COLOR_BGR2GRAY)
   img = cv2.resize(img, (160, 160), interpolation=cv2.INTER_LINEAR)
   img = img / 255.0
   img = np.asarray(img).astype('float32')
   ```

2. yolo è§£ç 

   `inference_yolo-s.py` ä¸­çš„ `yolo_decode` å‡½æ•°

   æ¨¡å‹æ¨ç†çš„æ˜¯æ£€æµ‹ç›®æ ‡çš„ `xywh` çš„åç§»é‡ï¼Œç›®çš„æ˜¯å°†æ¨¡å‹è¾“å‡ºç»“æœè½¬æ¢æˆçœŸå®ä¸–ç•Œçš„ `xywh`

   è¿™éƒ¨åˆ†å‘¢ï¼Œæˆ‘ä¹Ÿå†™äº†ä¸€ç¯‡æ–‡ç« ï¼Œæ„Ÿå…´è¶£çš„å¯ä»¥çœ‹ä¸€ä¸‹ï¼š[æŒæ¡ yolo - è§£ç æ ¸å¿ƒæ€æƒ³ï¼Œ](https://blog.csdn.net/weixin_37598106/article/details/113058426?spm=1001.2014.3001.5501)

3. nms

   `inference_yolo-s.py` ä¸­çš„ `non_max_suppress` å‡½æ•°ï¼Œè¿™ä¸ªå‡½æ•°é’ˆå¯¹çš„æ˜¯å•ç±»åˆ«çš„

---

c ä»£ç çš„å®ç°æ¯”è¾ƒç—›è‹¦ï¼Œï¼Œç—›è‹¦é¢å…· x3

- [x] ç°åº¦è½¬æ¢
- [x] å°ºåº¦ç¼©æ”¾
- [x] yolo è§£ç 
- [ ] nms ï¼ˆå¯èƒ½äº”ä¸€èŠ‚åå®ç°ï¼‰

1. ç°åº¦è½¬æ¢

   RGBè½¬ç°åº¦ï¼Œé€šå¸¸ä¼šä½¿ç”¨ä¸‹é¢çš„ä¸€ä¸ªå¿ƒç†å­¦å…¬å¼ï¼š(Matlabå’ŒOpenCVä¸­ä½¿ç”¨çš„ä¹Ÿæ˜¯è¯¥å…¬å¼)

   ```shell
   Gray = 0.2989*R + 0.5870*G + 0.1140*B
   # ä¼˜åŒ–
   Gray = ï¼ˆ2989*R + 5870*G + 1140*Bï¼‰/ 10000
   # ç§»ä½
   Gray = ï¼ˆ4898*R + 9618*G + 1868*Bï¼‰>> 14
   # 8ä½ç²¾åº¦
   Gray = ï¼ˆ76*R + 150*G + 30*Bï¼‰>> 8
   ```

   ```c
   // c ä»£ç å®ç°
   void rgb2gray(unsigned char *src,unsigned char *dst, int width,int height)
   {
       int r, g, b;
       for (int i=0; i<width*height; ++i)
       {
           r = *src++; // load red
           g = *src++; // load green
           b = *src++; // load blue
           // build weighted average:
           *dst++ = (r * 76 + g * 150 + b * 30) >> 8;
       }
   }
   ```

   ```python
   # python ä»£ç å®ç°
   # val_c_gray_scaling.py
   def img2gray(img_path):
       # è¯»å–ç¬¬ä¸€å¼ å›¾åƒ
       img = cv2.imread(img_path)
       # è·å–å›¾åƒå°ºå¯¸
       h, w = img.shape[0:2]
       # è‡ªå®šä¹‰ç©ºç™½å•é€šé“å›¾åƒï¼Œç”¨äºå­˜æ”¾ç°åº¦å›¾
       gray = np.zeros((h, w), dtype=img.dtype)
       # å¯¹åŸå›¾åƒè¿›è¡Œéå†ï¼Œç„¶ååˆ†åˆ«å¯¹B\G\RæŒ‰æ¯”ä¾‹ç°åº¦åŒ–
       for i in range(h):
           for j in range(w):
               gray[i, j] = 0.11 * img[i, j, 0] + 0.59 * img[i, j, 1] + 0.3 * img[i, j, 2]  # Y=0.3R+0.59G+0.11B
       show_img(gray)
       return gray
   ```

2. å°ºåº¦ç¼©æ”¾

   æ­¤å¤„ç”¨çš„æ˜¯åŒçº¿æ€§æ’å€¼

   ```c
   int is_in_array(short x, short y, short height, short width)
   {
       if (x >= 0 && x < width && y >= 0 && y < height)
           return 1;
       else
           return 0;
   }
   
   void bilinera_interpolation(rt_uint8_t* in_array, short height, short width, 
                               rt_uint8_t* out_array, short out_height, short out_width)
   {
       double h_times = (double)out_height / (double)height,
              w_times = (double)out_width / (double)width;
       short  x1, y1, x2, y2, f11, f12, f21, f22;
       double x, y;
   
       for (int i = 0; i < out_height; i++){
           for (int j = 0; j < out_width; j++){
               x = j / w_times;
               y = i / h_times;
             
               x1 = (short)(x - 1);
               x2 = (short)(x + 1);
               y1 = (short)(y + 1);
               y2 = (short)(y - 1);
               f11 = is_in_array(x1, y1, height, width) ? in_array[y1*width+x1] : 0;
               f12 = is_in_array(x1, y2, height, width) ? in_array[y2*width+x1] : 0;
               f21 = is_in_array(x2, y1, height, width) ? in_array[y1*width+x2] : 0;
               f22 = is_in_array(x2, y2, height, width) ? in_array[y2*width+x2] : 0;
               out_array[i*out_width+j] = (rt_uint8_t)(((f11 * (x2 - x) * (y2 - y)) +
                                          (f21 * (x - x1) * (y2 - y)) +
                                          (f12 * (x2 - x) * (y - y1)) +
                                          (f22 * (x - x1) * (y - y1))) / ((x2 - x1) * (y2 - y1)));
           }
       }
   }
   ```

   `python` ä»£ç å®ç°ï¼š`val_c_gray_scaling.py` ä¸­çš„ `bilinera_interpolation` å‡½æ•°

3. yolo è§£ç 

   ```c
   // c ä»£ç å®ç°
   // applications/yolo.c
   int yolo_decode(float *out_data)
   {
     int j=0,k=0,l=0;
     for(int i=0; i<5*5*5; i++)
     {
       float x_tmp = 1 / (1 + exp(-out_data[i*6+0]));
       float y_tmp = 1 / (1 + exp(-out_data[i*6+1]));
       float box_x = (x_tmp + k) / 5;
       float box_y = (y_tmp + l) / 5;
       
       float box_w = (exp(out_data[i*6+2])*anchor[j][0])/ input_dims[0];
       float box_h = (exp(out_data[i*6+3])*anchor[j][1])/ input_dims[1];
       
       float objectness = 1 / (1 + exp(-out_data[i*6+4]));
       
       float class_scores = 1 / (1 + exp(-out_data[i*6+5]));
      
   //    printf("%d %d %d %f %f, %f %f, %f %f\n", j,k,l, box_x, box_y, box_w, box_h, objectness, class_scores);
       
       out_data[i*6+0] = box_x;
       out_data[i*6+1] = box_y;
       out_data[i*6+2] = box_w;
       out_data[i*6+3] = box_h;
       out_data[i*6+4] = objectness;
       out_data[i*6+5] = class_scores;
       
       if(j++>=4)
       {
         j = 0;
         if(k++>=4)
         {
           k = 0;
           if(l++>=4)
           {
             l = 0;
           }
         }
       }
     }
     return 0;
   }
   ```

   python ä»£ç å®ç°ï¼š`inference_yolo-s.py` ä¸­çš„ `yolo_decode` å‡½æ•°

4. nms 

   æ²¡æœ‰ `nms` çš„ç›®æ ‡æ£€æµ‹å·¥ç¨‹å°±ç­‰äºæ²¡æœ‰çµé­‚ï¼Œï¼Œï¼Œç­‰åæœŸæ¥å®ç°

---

ç¼–è¯‘æŠ¥é”™ä»¥åŠè§£å†³

![](imgs\20210429171346.png)

ç¬¬äºŒç§è§£å†³æ–¹å¼ï¼š

![](imgs\20210429171821.png)

# 4. å‚è€ƒé“¾æ¥

- [C++ RGBè½¬ç°åº¦å›¾åƒ](https://blog.csdn.net/martinkeith/article/details/104185635)

- [GBeetle/c_image_processing/scaling/scaling.c](https://github.com/GBeetle/c_image_processing/blob/4ceabf4959f455f5b7d1ee419aac25eccf231b3b/scaling/scaling.c#L155)

